{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39b7e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({50: 583, 258: 509, 100: 508, 181: 507, 294: 485, 286: 481, 288: 478, 1: 452, 300: 431, 121: 429, 174: 420, 127: 413, 56: 394, 7: 392, 98: 390, 237: 384, 117: 378, 172: 367, 222: 365, 204: 350, 313: 350, 405: 344, 79: 336, 210: 331, 151: 326, 173: 324, 69: 321, 748: 316, 168: 316, 269: 315, 257: 303, 195: 301, 423: 300, 9: 299, 318: 298, 276: 298, 302: 297, 22: 297, 328: 295, 96: 295, 118: 293, 15: 293, 25: 293, 183: 291, 216: 290, 176: 284, 64: 283, 234: 280, 202: 280, 191: 276, 28: 276, 89: 275, 111: 272, 275: 268, 12: 267, 742: 267, 357: 264, 82: 261, 135: 259, 289: 259, 97: 256, 238: 256, 268: 255, 546: 254, 196: 251, 333: 251, 186: 251, 70: 251, 475: 250, 153: 247, 132: 246, 228: 244, 125: 244, 144: 243, 483: 243, 194: 241, 245: 240, 323: 240, 197: 239, 185: 239, 11: 236, 282: 232, 496: 231, 568: 230, 301: 230, 265: 227, 655: 227, 182: 226, 273: 223, 143: 222, 471: 221, 179: 221, 180: 221, 71: 220, 161: 220, 95: 219, 427: 219, 678: 219, 8: 219, 322: 218, 235: 217, 435: 216, 508: 215, 88: 213, 215: 212, 271: 211, 603: 209, 4: 209, 187: 209, 385: 208, 175: 208, 200: 206, 597: 206, 211: 206, 588: 202, 515: 201, 403: 201, 208: 200, 230: 199, 272: 198, 134: 198, 250: 197, 527: 195, 474: 194, 298: 194, 284: 193, 393: 192, 209: 191, 274: 190, 340: 189, 307: 188, 124: 187, 147: 185, 13: 184, 14: 183, 23: 182, 203: 182, 514: 180, 751: 180, 732: 180, 480: 179, 479: 179, 566: 179, 419: 178, 591: 178, 283: 177, 845: 176, 83: 176, 327: 175, 58: 175, 326: 175, 432: 174, 154: 174, 24: 174, 511: 173, 255: 172, 99: 172, 229: 171, 137: 171, 218: 171, 133: 171, 433: 171, 651: 171, 451: 170, 367: 170, 402: 170, 188: 170, 321: 169, 684: 169, 628: 169, 319: 168, 582: 168, 226: 166, 199: 165, 739: 164, 692: 164, 523: 164, 411: 163, 443: 162, 410: 162, 66: 162, 259: 162, 285: 162, 227: 161, 248: 160, 476: 160, 315: 160, 252: 158, 472: 158, 193: 157, 685: 157, 150: 157, 240: 156, 690: 155, 31: 154, 431: 153, 660: 153, 498: 152, 164: 151, 77: 151, 550: 151, 86: 150, 239: 150, 304: 149, 55: 149, 763: 149, 1028: 148, 462: 148, 156: 148, 42: 148, 293: 147, 654: 147, 281: 146, 455: 145, 310: 145, 332: 143, 91: 143, 358: 143, 231: 142, 484: 138, 87: 138, 1016: 137, 559: 137, 177: 137, 347: 137, 705: 137, 94: 137, 735: 137, 879: 136, 223: 136, 205: 136, 270: 136, 68: 134, 303: 134, 1047: 134, 213: 134, 47: 133, 243: 132, 2: 131, 657: 131, 109: 130, 249: 130, 531: 129, 129: 129, 418: 129, 72: 129, 241: 128, 756: 128, 325: 128, 53: 128, 73: 128, 148: 128, 482: 128, 198: 127, 62: 127, 291: 127, 596: 127, 157: 127, 260: 127, 346: 126, 473: 126, 485: 125, 178: 125, 324: 125, 116: 125, 246: 124, 526: 124, 750: 124, 520: 124, 343: 124, 190: 124, 233: 124, 501: 123, 504: 122, 509: 121, 447: 121, 510: 121, 428: 121, 528: 121, 170: 121, 217: 120, 38: 120, 521: 120, 746: 119, 631: 119, 866: 119, 169: 118, 242: 117, 48: 117, 449: 117, 184: 116, 663: 116, 380: 116, 192: 116, 65: 115, 762: 115, 659: 115, 123: 115, 29: 114, 214: 114, 292: 114, 331: 113, 815: 112, 408: 112, 93: 112, 316: 112, 219: 111, 382: 111, 81: 110, 225: 109, 470: 108, 679: 107, 122: 106, 421: 106, 162: 106, 895: 106, 136: 105, 54: 104, 478: 104, 709: 104, 92: 104, 928: 104, 67: 103, 317: 102, 554: 102, 699: 102, 747: 102, 232: 101, 264: 101, 378: 101, 404: 101, 926: 101, 708: 101, 159: 101, 381: 100, 665: 100, 682: 100, 1012: 100, 436: 99, 1014: 98, 507: 98, 155: 98, 33: 97, 126: 97, 429: 97, 356: 97, 919: 96, 755: 96, 306: 96, 290: 96, 477: 95, 131: 95, 90: 95, 576: 93, 430: 93, 820: 93, 412: 93, 1011: 93, 529: 93, 212: 92, 163: 92, 17: 92, 744: 92, 578: 92, 549: 92, 338: 91, 52: 91, 831: 91, 517: 91, 693: 91, 636: 91, 3: 90, 1039: 90, 506: 90, 652: 90, 458: 90, 201: 89, 518: 89, 10: 89, 642: 89, 399: 89, 661: 88, 715: 87, 305: 87, 39: 87, 386: 87, 689: 87, 5: 86, 673: 86, 720: 86, 864: 86, 792: 86, 988: 86, 465: 85, 280: 85, 425: 85, 448: 85, 924: 85, 21: 84, 781: 84, 59: 83, 825: 83, 625: 82, 662: 82, 640: 82, 823: 82, 717: 82, 152: 82, 63: 82, 51: 81, 32: 81, 604: 81, 873: 81, 49: 81, 729: 81, 420: 81, 930: 80, 312: 80, 826: 80, 530: 80, 45: 80, 519: 80, 658: 79, 44: 79, 696: 79, 710: 79, 584: 79, 287: 78, 736: 78, 295: 77, 676: 77, 629: 77, 1074: 77, 401: 76, 724: 76, 778: 76, 627: 75, 311: 75, 969: 75, 871: 75, 461: 74, 105: 74, 221: 74, 1101: 74, 26: 73, 417: 73, 299: 73, 1048: 73, 525: 73, 101: 73, 20: 72, 141: 72, 513: 72, 354: 72, 650: 72, 713: 72, 277: 71, 106: 71, 463: 71, 949: 71, 544: 71, 558: 70, 409: 70, 707: 70, 647: 70, 384: 69, 160: 69, 780: 69, 687: 69, 633: 69, 19: 69, 392: 68, 1035: 68, 505: 68, 80: 68, 497: 68, 487: 68, 934: 68, 648: 67, 371: 67, 120: 67, 491: 67, 569: 67, 114: 67, 469: 67, 167: 67, 434: 67, 452: 66, 220: 66, 790: 66, 189: 66, 207: 66, 855: 66, 1073: 66, 262: 66, 606: 66, 993: 66, 607: 66, 538: 66, 387: 65, 171: 65, 145: 65, 128: 65, 488: 65, 345: 65, 672: 65, 108: 65, 486: 64, 416: 64, 165: 64, 334: 64, 468: 64, 595: 64, 959: 64, 60: 64, 619: 64, 616: 64, 887: 64, 1009: 64, 740: 63, 516: 63, 450: 63, 553: 63, 481: 63, 727: 63, 1041: 62, 499: 62, 254: 62, 414: 62, 140: 61, 946: 61, 278: 60, 609: 60, 493: 60, 939: 60, 158: 60, 61: 59, 561: 59, 492: 59, 737: 59, 1119: 59, 581: 59, 615: 59, 880: 59, 495: 59, 391: 59, 716: 58, 741: 58, 632: 58, 923: 58, 85: 58, 166: 58, 898: 58, 722: 58, 40: 57, 512: 57, 770: 57, 142: 57, 931: 57, 27: 57, 754: 57, 827: 57, 502: 57, 813: 56, 494: 56, 395: 56, 344: 55, 847: 55, 369: 55, 413: 55, 721: 54, 396: 54, 102: 54, 535: 54, 76: 54, 675: 54, 892: 53, 849: 53, 1065: 53, 875: 53, 886: 53, 840: 53, 441: 53, 702: 53, 768: 52, 466: 52, 877: 52, 489: 52, 342: 52, 749: 51, 712: 51, 542: 51, 614: 51, 649: 50, 1017: 50, 206: 50, 686: 50, 806: 50, 602: 50, 139: 50, 490: 50, 570: 50, 297: 50, 955: 49, 406: 49, 824: 49, 977: 49, 683: 49, 772: 49, 833: 49, 541: 49, 365: 48, 948: 48, 674: 48, 244: 48, 1228: 48, 456: 48, 841: 48, 562: 48, 467: 48, 366: 47, 789: 47, 339: 47, 363: 47, 1007: 47, 876: 47, 1118: 47, 794: 46, 941: 46, 251: 46, 1046: 46, 524: 46, 671: 46, 921: 46, 760: 46, 1135: 46, 444: 46, 664: 46, 956: 46, 1079: 45, 1197: 45, 552: 45, 942: 45, 810: 45, 728: 45, 329: 45, 236: 45, 952: 45, 881: 45, 688: 44, 984: 44, 1067: 44, 1010: 44, 761: 44, 1142: 44, 539: 44, 846: 44, 575: 44, 975: 44, 1025: 44, 638: 44, 224: 44, 656: 44, 694: 44, 1188: 44, 896: 44, 379: 43, 944: 43, 1091: 43, 407: 43, 809: 43, 540: 43, 620: 43, 589: 43, 336: 43, 261: 43, 1050: 43, 890: 43, 1098: 42, 872: 42, 900: 42, 107: 42, 769: 42, 844: 42, 902: 42, 577: 41, 1110: 41, 350: 41, 963: 41, 1063: 41, 355: 41, 547: 41, 771: 41, 330: 41, 610: 41, 1051: 41, 57: 40, 611: 40, 943: 40, 945: 40, 43: 40, 929: 40, 1044: 40, 697: 40, 932: 40, 819: 40, 802: 40, 639: 40, 785: 39, 16: 39, 1217: 39, 623: 39, 951: 39, 731: 39, 1060: 39, 370: 39, 585: 39, 874: 39, 743: 39, 752: 39, 622: 39, 373: 39, 503: 39, 1221: 39, 1134: 38, 1021: 38, 1013: 38, 1210: 38, 646: 38, 1089: 38, 637: 38, 937: 37, 583: 37, 364: 37, 30: 37, 41: 37, 1090: 37, 783: 37, 1008: 37, 796: 36, 670: 36, 856: 36, 1244: 36, 979: 35, 522: 35, 644: 35, 1059: 35, 567: 35, 1020: 35, 266: 35, 829: 34, 612: 34, 922: 34, 680: 34, 961: 34, 586: 34, 372: 34, 723: 34, 971: 34, 882: 34, 653: 34, 925: 34, 1267: 33, 78: 33, 573: 33, 641: 33, 1139: 33, 990: 33, 878: 33, 1018: 32, 1022: 32, 774: 32, 974: 32, 1033: 32, 580: 32, 426: 32, 765: 32, 1132: 32, 936: 32, 940: 32, 1126: 32, 1226: 32, 989: 32, 368: 31, 110: 31, 995: 31, 779: 31, 1019: 31, 808: 31, 738: 31, 605: 31, 630: 31, 797: 31, 1194: 31, 500: 31, 383: 31, 349: 31, 1023: 31, 1220: 30, 1133: 30, 950: 30, 308: 30, 843: 30, 1215: 30, 608: 30, 537: 30, 1137: 29, 719: 29, 1115: 29, 1061: 29, 572: 29, 764: 29, 1095: 29, 563: 29, 1136: 29, 1042: 28, 460: 28, 279: 28, 1109: 28, 571: 28, 309: 28, 1129: 28, 1411: 28, 362: 28, 972: 28, 1152: 28, 388: 28, 564: 27, 842: 27, 905: 27, 1070: 27, 1034: 27, 457: 27, 464: 27, 348: 27, 805: 27, 1170: 27, 389: 27, 978: 27, 613: 27, 734: 27, 681: 27, 645: 27, 46: 27, 836: 26, 1240: 26, 1160: 26, 253: 26, 1218: 26, 1284: 26, 775: 26, 1149: 26, 352: 26, 966: 26, 6: 26, 398: 26, 422: 26, 800: 26, 1049: 25, 960: 25, 938: 25, 1052: 25, 1157: 25, 1222: 25, 991: 25, 1163: 25, 415: 25, 818: 25, 1040: 25, 834: 25, 837: 25, 1045: 25, 869: 24, 376: 24, 634: 24, 1037: 24, 863: 24, 704: 24, 1053: 24, 1036: 24, 551: 24, 753: 24, 459: 24, 730: 24, 375: 23, 1006: 23, 1199: 23, 1315: 23, 149: 23, 1093: 23, 635: 23, 962: 23, 986: 23, 1258: 23, 1054: 23, 130: 23, 832: 22, 1078: 22, 953: 22, 1057: 22, 821: 22, 1005: 22, 980: 22, 624: 22, 560: 22, 532: 22, 1113: 22, 445: 22, 1168: 22, 565: 22, 985: 22, 1231: 22, 1176: 22, 1147: 21, 1086: 21, 758: 21, 543: 21, 335: 21, 906: 21, 965: 21, 816: 21, 1084: 21, 1203: 21, 795: 21, 865: 21, 933: 21, 1121: 21, 982: 20, 908: 20, 904: 20, 1208: 20, 320: 20, 1030: 20, 1407: 20, 351: 20, 601: 20, 112: 20, 1296: 20, 1219: 20, 1444: 19, 1153: 19, 1248: 19, 1178: 19, 1245: 19, 138: 19, 703: 19, 263: 19, 424: 19, 1206: 19, 1183: 19, 1117: 19, 894: 19, 579: 19, 1265: 19, 1283: 19, 1277: 19, 1103: 19, 903: 18, 812: 18, 617: 18, 337: 18, 1107: 18, 618: 18, 590: 18, 1230: 18, 811: 18, 84: 18, 1069: 18, 359: 18, 1105: 18, 1478: 18, 1097: 18, 1239: 18, 1401: 18, 968: 18, 1303: 18, 862: 18, 916: 18, 400: 18, 1185: 18, 1204: 18, 1286: 17, 773: 17, 1207: 17, 1001: 17, 947: 17, 557: 17, 1120: 17, 1232: 17, 1140: 17, 1038: 17, 256: 16, 725: 16, 860: 16, 454: 16, 1278: 16, 718: 16, 745: 16, 997: 16, 453: 16, 1066: 16, 691: 16, 801: 16, 1419: 16, 1032: 16, 1071: 16, 854: 16, 998: 16, 1280: 16, 1311: 16, 1451: 15, 835: 15, 1209: 15, 115: 15, 103: 15, 1263: 15, 983: 15, 859: 15, 533: 15, 1291: 15, 700: 15, 574: 15, 1112: 15, 1172: 15, 733: 15, 1024: 15, 888: 15, 1446: 15, 1143: 15, 1285: 15, 1058: 15, 1273: 15, 587: 14, 440: 14, 1165: 14, 853: 14, 786: 14, 958: 14, 996: 14, 1225: 14, 353: 14, 893: 14, 726: 14, 1313: 14, 1029: 14, 1171: 14, 377: 13, 787: 13, 695: 13, 1099: 13, 1161: 13, 1229: 13, 36: 13, 714: 13, 1281: 13, 1182: 13, 1116: 13, 883: 13, 915: 13, 828: 13, 1131: 13, 1187: 13, 1192: 13, 1128: 13, 889: 13, 1088: 13, 885: 13, 669: 13, 1404: 13, 534: 13, 909: 13, 1211: 12, 1224: 12, 1015: 12, 901: 12, 593: 12, 1428: 12, 397: 12, 1094: 12, 1249: 12, 556: 12, 1518: 12, 1266: 12, 548: 12, 394: 12, 976: 12, 1062: 12, 1124: 12, 1297: 12, 1166: 12, 967: 12, 1068: 12, 667: 12, 545: 12, 1469: 12, 1076: 12, 1092: 12, 1154: 12, 1483: 12, 767: 11, 374: 11, 621: 11, 341: 11, 1314: 11, 954: 11, 1127: 11, 1190: 11, 759: 11, 1254: 11, 1480: 11, 1167: 11, 1085: 11, 1274: 11, 35: 11, 914: 11, 1195: 11, 1421: 11, 1159: 11, 1335: 11, 1184: 10, 1336: 10, 360: 10, 146: 10, 1181: 10, 1114: 10, 793: 10, 361: 10, 536: 10, 1180: 10, 791: 10, 1000: 10, 1169: 10, 999: 10, 782: 10, 1268: 10, 555: 10, 1503: 10, 390: 10, 698: 10, 1425: 10, 18: 10, 1087: 10, 1056: 10, 701: 10, 1193: 10, 1434: 10, 1400: 10, 1375: 10, 1269: 10, 1540: 10, 1055: 10, 1615: 10, 1393: 9, 870: 9, 1150: 9, 807: 9, 113: 9, 848: 9, 1298: 9, 766: 9, 267: 9, 1179: 9, 1471: 9, 964: 9, 1141: 9, 1004: 9, 776: 9, 1282: 9, 1300: 9, 1473: 9, 592: 9, 1148: 9, 803: 9, 1279: 9, 798: 9, 1252: 9, 912: 9, 1214: 9, 1337: 9, 1437: 9, 899: 9, 1415: 9, 446: 9, 1620: 9, 1145: 9, 1081: 8, 1100: 8, 1003: 8, 37: 8, 1299: 8, 918: 8, 1262: 8, 1082: 8, 1413: 8, 1043: 8, 1002: 8, 1227: 8, 1202: 8, 1276: 8, 1077: 8, 970: 8, 1479: 8, 1449: 8, 1524: 8, 1439: 8, 804: 8, 1174: 8, 1238: 8, 1426: 8, 981: 8, 1255: 8, 1381: 8, 1475: 8, 1234: 8, 1251: 8, 1295: 7, 1462: 7, 1246: 7, 1198: 7, 1288: 7, 1151: 7, 1316: 7, 34: 7, 1376: 7, 1289: 7, 1394: 7, 74: 7, 884: 7, 1102: 7, 1072: 7, 1312: 7, 1253: 7, 1270: 7, 1459: 7, 1409: 7, 1294: 7, 1527: 7, 994: 7, 1271: 7, 1177: 7, 1379: 7, 1075: 7, 1456: 7, 1531: 7, 1441: 7, 1264: 7, 935: 7, 1200: 7, 1305: 7, 1435: 7, 1522: 7, 1031: 7, 917: 7, 1111: 7, 1399: 7, 1173: 7, 1514: 7, 1558: 7, 1243: 7, 927: 6, 1216: 6, 1383: 6, 1164: 6, 1250: 6, 1322: 6, 867: 6, 1328: 6, 1241: 6, 1212: 6, 1386: 6, 1213: 6, 1083: 6, 1368: 6, 1466: 6, 1247: 6, 1388: 6, 1405: 6, 706: 6, 668: 6, 1534: 6, 1454: 6, 891: 6, 1395: 6, 1591: 6, 1237: 6, 296: 6, 1512: 6, 1287: 6, 1412: 6, 1468: 6, 1355: 6, 1326: 6, 1598: 6, 438: 6, 1205: 6, 1474: 6, 1233: 6, 1380: 6, 439: 5, 868: 5, 1162: 5, 1346: 5, 1397: 5, 1324: 5, 1416: 5, 314: 5, 104: 5, 1242: 5, 1442: 5, 1108: 5, 1272: 5, 1495: 5, 1487: 5, 1378: 5, 437: 5, 1489: 5, 1529: 5, 1175: 5, 594: 5, 1367: 5, 1427: 5, 1385: 5, 1438: 5, 247: 5, 1301: 5, 1353: 5, 1530: 5, 1302: 5, 1396: 5, 75: 5, 1555: 5, 1344: 5, 1392: 5, 1517: 5, 1470: 5, 1406: 5, 1501: 5, 1333: 5, 1138: 5, 920: 5, 1592: 5, 1496: 5, 1597: 5, 1431: 5, 666: 5, 1511: 5, 1440: 5, 799: 5, 1509: 5, 626: 4, 1260: 4, 643: 4, 839: 4, 838: 4, 777: 4, 1347: 4, 1104: 4, 1106: 4, 850: 4, 910: 4, 119: 4, 992: 4, 1259: 4, 598: 4, 1403: 4, 822: 4, 1158: 4, 1125: 4, 1485: 4, 1223: 4, 1443: 4, 1330: 4, 1338: 4, 442: 4, 1369: 4, 1257: 4, 1521: 4, 1377: 4, 1275: 4, 1317: 4, 1261: 4, 1064: 4, 757: 4, 1545: 4, 1537: 4, 1331: 4, 1589: 4, 1422: 4, 1608: 4, 1026: 4, 1560: 4, 1402: 4, 1499: 4, 1445: 4, 1539: 4, 1605: 4, 1488: 4, 973: 4, 1553: 4, 851: 4, 1319: 4, 1535: 4, 1612: 4, 1628: 4, 1600: 4, 1410: 4, 1423: 4, 1429: 4, 1643: 4, 987: 4, 1664: 4, 911: 4, 1382: 4, 858: 3, 1327: 3, 1186: 3, 1464: 3, 1351: 3, 1424: 3, 1189: 3, 1484: 3, 1292: 3, 788: 3, 1508: 3, 1372: 3, 1463: 3, 1384: 3, 1318: 3, 1123: 3, 1370: 3, 861: 3, 1430: 3, 1361: 3, 1387: 3, 1432: 3, 1357: 3, 1538: 3, 817: 3, 1418: 3, 1504: 3, 1391: 3, 1096: 3, 1293: 3, 1389: 3, 1513: 3, 1420: 3, 1506: 3, 1528: 3, 1191: 3, 1465: 3, 1146: 3, 1516: 3, 1623: 3, 1408: 3, 1602: 3, 1155: 3, 1323: 3, 1609: 3, 1552: 3, 1607: 3, 1610: 3, 1144: 3, 1490: 3, 1027: 3, 1639: 3, 1196: 3, 1658: 3, 1652: 3, 1256: 3, 1544: 3, 1622: 3, 1356: 3, 1448: 3, 1497: 2, 1332: 2, 1334: 2, 1350: 2, 1436: 2, 1342: 2, 1306: 2, 913: 2, 1362: 2, 1500: 2, 1371: 2, 1390: 2, 907: 2, 784: 2, 1374: 2, 1417: 2, 1578: 2, 1398: 2, 1354: 2, 1554: 2, 1307: 2, 1455: 2, 1477: 2, 1360: 2, 1519: 2, 1450: 2, 1550: 2, 1472: 2, 1308: 2, 1523: 2, 1080: 2, 1290: 2, 1547: 2, 1304: 2, 1359: 2, 1588: 2, 1590: 2, 1617: 2, 957: 2, 1549: 2, 600: 2, 1585: 2, 1532: 2, 1358: 2, 1502: 2, 1541: 2, 1345: 2, 1656: 2, 1321: 2, 1491: 2, 1642: 2, 1629: 2, 1481: 2, 1644: 2, 897: 2, 1365: 2, 1662: 2, 1646: 2, 1467: 2, 1672: 2, 1433: 2, 1573: 2, 1551: 2, 1631: 2, 1542: 2, 1556: 2, 1611: 2, 1594: 2, 1348: 1, 1320: 1, 1492: 1, 1364: 1, 1493: 1, 830: 1, 1498: 1, 814: 1, 1520: 1, 711: 1, 1373: 1, 1309: 1, 857: 1, 1236: 1, 1310: 1, 1536: 1, 1582: 1, 1343: 1, 1457: 1, 1543: 1, 599: 1, 1458: 1, 1561: 1, 1533: 1, 1565: 1, 1563: 1, 1156: 1, 1505: 1, 852: 1, 1557: 1, 1562: 1, 1586: 1, 1476: 1, 1580: 1, 1363: 1, 1339: 1, 1566: 1, 1349: 1, 1447: 1, 1235: 1, 1587: 1, 677: 1, 1571: 1, 1575: 1, 1510: 1, 1579: 1, 1603: 1, 1616: 1, 1526: 1, 1596: 1, 1453: 1, 1461: 1, 1559: 1, 1507: 1, 1593: 1, 1576: 1, 1525: 1, 1569: 1, 1568: 1, 1340: 1, 1619: 1, 1601: 1, 1583: 1, 1624: 1, 1651: 1, 1414: 1, 1486: 1, 1614: 1, 1570: 1, 1599: 1, 1649: 1, 1572: 1, 1653: 1, 1452: 1, 1595: 1, 1548: 1, 1655: 1, 1654: 1, 1482: 1, 1657: 1, 1650: 1, 1660: 1, 1661: 1, 1515: 1, 1621: 1, 1632: 1, 1618: 1, 1647: 1, 1581: 1, 1584: 1, 1669: 1, 1613: 1, 1130: 1, 1663: 1, 1634: 1, 1606: 1, 1329: 1, 1494: 1, 1673: 1, 1633: 1, 1677: 1, 1679: 1, 1577: 1, 1666: 1, 1635: 1, 1648: 1, 1678: 1, 1567: 1, 1122: 1, 1201: 1, 1546: 1, 1627: 1, 1676: 1, 1680: 1, 1366: 1, 1668: 1, 1564: 1, 1604: 1, 1574: 1, 1671: 1, 1625: 1, 1665: 1, 1325: 1, 1670: 1, 1341: 1, 1352: 1, 1636: 1, 1681: 1, 1638: 1, 1667: 1, 1675: 1, 1460: 1, 1626: 1, 1645: 1, 1659: 1, 1682: 1, 1674: 1, 1640: 1, 1637: 1, 1630: 1, 1641: 1})\n",
      "ratings less than  50 : 1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user Toy Story (1995);1 GoldenEye (1995);2 Four Rooms (1995);3  \\\n",
      "1    1                  5                  3                   4   \n",
      "2    2                  4                  0                   0   \n",
      "3    3                  0                  0                   0   \n",
      "4    4                  0                  0                   0   \n",
      "5    5                  4                  3                   0   \n",
      "\n",
      "  Get Shorty (1995);4 Copycat (1995);5 Twelve Monkeys (1995);7 Babe (1995);8  \\\n",
      "1                   3                3                       4             1   \n",
      "2                   0                0                       0             0   \n",
      "3                   0                0                       0             0   \n",
      "4                   0                0                       0             0   \n",
      "5                   0                0                       0             0   \n",
      "\n",
      "  Dead Man Walking (1995);9 Richard III (1995);10  ...  \\\n",
      "1                         5                     3  ...   \n",
      "2                         0                     2  ...   \n",
      "3                         0                     0  ...   \n",
      "4                         0                     0  ...   \n",
      "5                         0                     0  ...   \n",
      "\n",
      "  Cool Runnings (1993);1035 Hamlet (1996);1039 Forget Paris (1995);1041  \\\n",
      "1                         0                  0                        0   \n",
      "2                         0                  0                        0   \n",
      "3                         0                  0                        0   \n",
      "4                         0                  0                        0   \n",
      "5                         0                  0                        0   \n",
      "\n",
      "  Multiplicity (1996);1047 She's the One (1996);1048  \\\n",
      "1                        0                         0   \n",
      "2                        0                         0   \n",
      "3                        0                         0   \n",
      "4                        0                         0   \n",
      "5                        0                         0   \n",
      "\n",
      "  Koyaanisqatsi (1983);1065 Shallow Grave (1994);1073  \\\n",
      "1                         0                         0   \n",
      "2                         0                         0   \n",
      "3                         0                         0   \n",
      "4                         0                         0   \n",
      "5                         0                         0   \n",
      "\n",
      "  Reality Bites (1994);1074 Six Degrees of Separation (1993);1101  \\\n",
      "1                         0                                     0   \n",
      "2                         0                                     0   \n",
      "3                         0                                     0   \n",
      "4                         0                                     0   \n",
      "5                         0                                     0   \n",
      "\n",
      "  Some Kind of Wonderful (1987);1119  \n",
      "1                                  0  \n",
      "2                                  0  \n",
      "3                                  0  \n",
      "4                                  0  \n",
      "5                                  0  \n",
      "\n",
      "[5 rows x 604 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>Toy Story (1995);1</th>\n",
       "      <th>GoldenEye (1995);2</th>\n",
       "      <th>Four Rooms (1995);3</th>\n",
       "      <th>Get Shorty (1995);4</th>\n",
       "      <th>Copycat (1995);5</th>\n",
       "      <th>Twelve Monkeys (1995);7</th>\n",
       "      <th>Babe (1995);8</th>\n",
       "      <th>Dead Man Walking (1995);9</th>\n",
       "      <th>Richard III (1995);10</th>\n",
       "      <th>...</th>\n",
       "      <th>Cool Runnings (1993);1035</th>\n",
       "      <th>Hamlet (1996);1039</th>\n",
       "      <th>Forget Paris (1995);1041</th>\n",
       "      <th>Multiplicity (1996);1047</th>\n",
       "      <th>She's the One (1996);1048</th>\n",
       "      <th>Koyaanisqatsi (1983);1065</th>\n",
       "      <th>Shallow Grave (1994);1073</th>\n",
       "      <th>Reality Bites (1994);1074</th>\n",
       "      <th>Six Degrees of Separation (1993);1101</th>\n",
       "      <th>Some Kind of Wonderful (1987);1119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  Toy Story (1995);1  GoldenEye (1995);2  Four Rooms (1995);3  \\\n",
       "0     1                   5                   3                    4   \n",
       "1     2                   4                   0                    0   \n",
       "\n",
       "   Get Shorty (1995);4  Copycat (1995);5  Twelve Monkeys (1995);7  \\\n",
       "0                    3                 3                        4   \n",
       "1                    0                 0                        0   \n",
       "\n",
       "   Babe (1995);8  Dead Man Walking (1995);9  Richard III (1995);10  ...  \\\n",
       "0              1                          5                      3  ...   \n",
       "1              0                          0                      2  ...   \n",
       "\n",
       "   Cool Runnings (1993);1035  Hamlet (1996);1039  Forget Paris (1995);1041  \\\n",
       "0                          0                   0                         0   \n",
       "1                          0                   0                         0   \n",
       "\n",
       "   Multiplicity (1996);1047  She's the One (1996);1048  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "\n",
       "   Koyaanisqatsi (1983);1065  Shallow Grave (1994);1073  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "\n",
       "   Reality Bites (1994);1074  Six Degrees of Separation (1993);1101  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "\n",
       "   Some Kind of Wonderful (1987);1119  \n",
       "0                                   0  \n",
       "1                                   0  \n",
       "\n",
       "[2 rows x 604 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#基于内容过滤（CBF）、协同过滤（CF）\n",
    "#效用矩阵：表示用户喜欢商品的程度的数据矩阵\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import collections\n",
    "from scipy import linalg\n",
    "import math\n",
    "from collections import defaultdict\n",
    "#导入商品数据\n",
    "df = pd.read_csv('./data/ml-100k/u.data',encoding='ISO-8859-1',sep='\\t',header=None)\n",
    "df_info = pd.read_csv('./data/ml-100k/u.item',encoding='ISO-8859-1',sep='|',header=None)\n",
    "movielist = [df_info[1].tolist()[indx]+';'+str(indx+1) for indx in range(len(df_info[1].tolist()))]\n",
    "nmovies = len(movielist)\n",
    "nusers = len(df[0].drop_duplicates().tolist())#去重并转为list\n",
    "min_ratings = 50\n",
    "movies_rated  = list(df[1]) \n",
    "counts = collections.Counter(movies_rated)\n",
    "print(counts)\n",
    "print('ratings less than ',min_ratings,':',len(collections.Counter(el for el in counts.elements() if counts[el] <min_ratings)))\n",
    "dfout = pd.DataFrame(columns=['user']+movielist)\n",
    "toremovelist = []\n",
    "for i in range(1,nusers):\n",
    "    tmpmovielist = [0 for j in range(nmovies)]\n",
    "    dftmp =df[df[0]==i]\n",
    "    for k in dftmp.index:\n",
    "        if counts[dftmp.loc[k][1]]>= min_ratings:           \n",
    "           tmpmovielist[dftmp.loc[k][1]-1] = dftmp.loc[k][2]\n",
    "        else:\n",
    "           toremovelist.append(dftmp.loc[k][1])\n",
    "            \n",
    "    dfout.loc[i] = [i]+tmpmovielist\n",
    "  \n",
    "toremovelist = list(set(toremovelist))\n",
    "dfout.drop(dfout.columns[toremovelist], axis=1, inplace=True)\n",
    "print(dfout.head())\n",
    "dfout.to_csv('data/utilitymatrix.csv',index=None)\n",
    "df = pd.read_csv('./data/utilitymatrix.csv')\n",
    "df.head(2)\n",
    "#0表示缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d788ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对缺失值赋予初始值：用户给出的平均分或每件商品的平均分\n",
    "def imputation(inp,Ri):\n",
    "    Ri = Ri.astype(float)\n",
    "    def userav():\n",
    "        for i in range(len(Ri)):\n",
    "            Ri[i][Ri[i]==0]=sum(Ri[i])/float(len(Ri[i][Ri[i]>0]))#将所有为0的缺失值赋值为用户的平均分\n",
    "            return Ri\n",
    "    def itemav():\n",
    "        for i in range(len(Ri[0])):\n",
    "            Ri[:,i][Ri[:,i]==0]=sum(Ri[:,i])/float(len(Ri[:,i][Ri[:,i]>0]))#缺失值赋值为每件商品的平均分\n",
    "        return Ri\n",
    "    switch = {'useraverage':userav(),'itemaverage':itemav()}\n",
    "    return switch(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9a026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#相似度度量方法:余弦相似度、皮尔逊相关系数，均值为0两种方法结果相同\n",
    "#计算两个向量之间的相似度函数（下）\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "def sim(x,y,metrix='cos'):\n",
    "    if metrix == 'cos':\n",
    "        return 1.-cosine(x,y)\n",
    "    else:\n",
    "        return pearsonr(x,y)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d4e6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于用户的协同过滤\n",
    "#使用KNN算法找出与给定用户打分记录相似的用户，对打分取加权平均值\n",
    "#（1）用相似度度量方法找出相似用户（2）对于没有打分的商品使用打分的加权平均值\n",
    "def CF_userbased(u_vec,K,data,index=False):\n",
    "    def FindKNeighbours(r,data,K):\n",
    "        neighs = []\n",
    "        cnt = 0\n",
    "        for u in range(len(data)):\n",
    "            if data[u,r]>0 and cnt<K:\n",
    "                neighs.append(data[u])\n",
    "                cnt+=1\n",
    "            elif cnt==X:\n",
    "                break\n",
    "        return np.array(neighs)\n",
    "    def CalcRating(u_vec,r,neighs):    #计算预测值\n",
    "        rating = 0\n",
    "        den = 0\n",
    "        for j in range(len(neighs)):\n",
    "            rating += neighs[j][-1]*float(neighs[j][r]-neighs[j][neighs[j]>0][:-1].mean())\n",
    "            den += abs(neighs[j][-1])\n",
    "        if den>0:\n",
    "            rating = np.round(u_vec[u_vec>0].mean()+(rating/den),0)\n",
    "        else:\n",
    "            rating = np.round(u_vec[u_vec>0].mean(),0)\n",
    "        if rating>5:\n",
    "            return 5\n",
    "        elif rating<1:\n",
    "            return 1\n",
    "        return rating\n",
    "    #添加相似列\n",
    "    data = data.astype(float)\n",
    "    nrows = len(data)\n",
    "    ncols = len(data[0])\n",
    "    data_sim = np.zeros((nrows,ncols+1))\n",
    "    data_sim[:,:-1] = data\n",
    "    \n",
    "    for u in range(nrows):           #计算用户打的分数与\n",
    "        if np.array_equal(data_sim[u,:-1],u_vec)==False:   \n",
    "            data_sim[u,ncols] = sim(data_sim[u,:-1],u_vec,'pearson')\n",
    "        else:\n",
    "            data_sim[u,ncols] = 0.\n",
    "    data_sim = data_sim[data_sim[:,ncols].argsort()][::-1]\n",
    "    for r in range(ncols):\n",
    "        if u_vec[r] == 0:\n",
    "            neighs = FindKNeighbours(r,data_sim,K)\n",
    "            u_vec[r] = CalcRating(u_vec,r,neighs)\n",
    "    if indxs:\n",
    "        seenindxs = [indx for indx in range(len(u_vec)) if u_vec[indx]>0]\n",
    "        u_vec[seenindxs] = -1\n",
    "        recsvec = np.argsort(u_vec)[::-1][np.argsort(u_vec)>0]\n",
    "        \n",
    "        return recsvec\n",
    "    return u_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66daafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于商品的协同过滤\n",
    "#（1）使用一种相似度度量方法，找出用户i打过分的商品最相似的K件商品\n",
    "#计算K件商品分数加权平均值，作为预测值\n",
    "class CF_itembased(object):\n",
    "    def _init_(self,data):\n",
    "        nitem = len(data[0])\n",
    "        self.data = data\n",
    "        self.simmatrix = np.zeros((nitems,nitems))\n",
    "        for i in range(nitems):\n",
    "            for j in range(nitems):\n",
    "                if j>=1:\n",
    "                    self.simmatrix[i,j] = sim(data[:,i],data[:,j])\n",
    "                else:\n",
    "                    self.simmatrix[i,j] = self.simmatrix[j,i]\n",
    "    def GetKSimItemsperUser(self,r,K,u_vec):        #找到K个近邻的商品\n",
    "        items = np.argsort(self.simmatrix[r])[::-1]\n",
    "        items = items[items!=r]\n",
    "        cnt = 0\n",
    "        neighitems = []\n",
    "        for i in items:\n",
    "            if u_vec[i]>0 and cnd<K:\n",
    "                neighitems.append(i)\n",
    "                cnt+=1\n",
    "            elif cnt==K:\n",
    "                break\n",
    "        return neighitems\n",
    "    def CalcRating(self,r,u_vec,neighitems):\n",
    "        rating = 0\n",
    "        den = 0\n",
    "        for i in neighitems:\n",
    "            rating += self.simmatrix[r,i]*u_vec[i]\n",
    "            den += abs(self.simmatrix[r,i])\n",
    "        if den>0:\n",
    "            rating = np.round(rating/den,0)\n",
    "        else:\n",
    "            rating = np.round(self.data[:,r][self.data[:,r]>0].mean(),0)\n",
    "        return rating\n",
    "    def CalcRatings(self,u_vec,K,indx = False):\n",
    "        u_rec = np.zeros(len(u_vec))\n",
    "        for r in range(len(u_vec)):\n",
    "            if u_vec[r] == 0:\n",
    "                neighitems = self.GetKSimItemsperUser(r,K,u_vec)\n",
    "                u_rec[r] = self.CalcRatings(r,u_vec,neighitems)\n",
    "        if indxs:\n",
    "            seenindxs = [indx for indx in range(len(u_vec)) if u_vec[indx]>0]\n",
    "            u_vec[seenindxs] = -1\n",
    "            recsvec = np.argsort(u_rec)[::-1][np.argsort(u_rec)>0]\n",
    "            \n",
    "            return recsvec\n",
    "        return u_rec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01c43bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope one算法（最简单的基于商品的协同过滤）\n",
    "#通过计算得到矩阵D，Dij表示商品i与商品j的平均差值\n",
    "#（1）找出与商品j差值最小的K件商品，计算加权平均值作为预测值\n",
    "class SlopeOne(object):\n",
    "    def _init_(self,Umatrix):\n",
    "        nitem = len(Umatrix[0])\n",
    "        self.dif,matrix = np.zeros((nitems,nitems))\n",
    "        self.nratings = np.zeros((nitems,nitems))\n",
    "        def diffav_n(x,y):\n",
    "            xy = np.vstack((x,y)).T\n",
    "            xy = xy[(xy[:,0]>0)&(xy[:,1]>0)]\n",
    "            nxy = len(xy)\n",
    "            if nxy==0:\n",
    "                return [1000.,0]\n",
    "            return [float(sum(xy[:,0]))/nxy,nxy]\n",
    "        for i in range(nitems):\n",
    "            for j in range(nitems):\n",
    "                if j>=1:\n",
    "                    self.difmatrix[i,j],self.nratings[i,j] = diffac_n(Umatrix[:,i],Umatrix[:,j])\n",
    "                else:\n",
    "                    self.difmatrix[i,j] = -self.difmatrix[j,i]\n",
    "                    self.nratings[i,j] = self.nrating[j,i]\n",
    "                    \n",
    "    def GetKSimItemsperUser(self,r,K,u_vec):        #找到K个近邻的商品\n",
    "        items = np.argsort(self.difmatrix[r])\n",
    "        items = items[items!=r]\n",
    "        cnt = 0\n",
    "        neighitems = []\n",
    "        for i in items:\n",
    "            if u_vec[i]>0 and cnd<K:\n",
    "                neighitems.append(i)\n",
    "                cnt+=1\n",
    "            elif cnt==K:\n",
    "                break\n",
    "        return neighitems\n",
    "    def CalcRating(self,r,u_vec,neighitems):\n",
    "        rating = 0\n",
    "        den = 0\n",
    "        for i in neighitems:\n",
    "            if abs(self.difmatrix[r,i])!=1000:\n",
    "                rating += (self.difmatrix[r,i]+u_vec[i])*self.nratings[r,i]\n",
    "                den += self.nratings[r,i]\n",
    "        if den==0:\n",
    "            return 0.\n",
    "        rating = np.round(rating/den,0)\n",
    "        if rating>5:\n",
    "            return 5\n",
    "        elif rating<1.:\n",
    "            return 1.\n",
    "        return rating\n",
    "    def CalcRatings(self,u_vec,K):\n",
    "        u_rec = np.zeros(len(u_vec))\n",
    "        for r in range(len(u_vec)):\n",
    "            if u_vec[r] == 0:\n",
    "                neighitems = self.GetKSimItemsperUser(r,K,u_vec)\n",
    "                u_rec[r] = self.CalcRating(r,u_vec,neighitems)\n",
    "        return u_rec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd414035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于模型的协同过滤\n",
    "#利用效用矩阵生成模型，抽取用户的打分模式。包含各种模式的模型返回预测值，填充或逼近原始矩阵（矩阵分解）\n",
    "#交替最小二乘（ALS）\n",
    "\n",
    "def ALS(Umatrix,K,iterations=50,l=0.001,tol=0.001):\n",
    "    nrows = len(Umatrix)\n",
    "    ncols = len(Umatrix[0])\n",
    "    P = np.random.rand(nrows,K)\n",
    "    Q = np.random.rand(ncols,K)\n",
    "    Qt = Q.T\n",
    "    err = 0.\n",
    "    Umatrix = Umatrix.astype(float)\n",
    "    mask = Umatrix>0\n",
    "    mask[mask==True] = 1\n",
    "    mask[mask==False] = 0\n",
    "    mask = mask.astype(np.float64,copy = False)\n",
    "    for it in range(iterations):\n",
    "        for u,mask_u in enumerate(mask):  #矩阵的形式计算线性方程\n",
    "            P[u] = np.linalg.solve(np.dot(Qt,np.dot(np.diag(mask_u),Qt.T))\n",
    "                                   +l*np.eye(K),np.dot(Qt,np.dot(np.diag(mask_u),Umatrix[u].T))).T\n",
    "        for i,mask_i in enumerate(mask.T):\n",
    "            Qt[:,i]  =np.linalg.solve(np.dot(P.T,np.dot(np.diag(mask_i),P))\n",
    "                                   +l*np.eye(K),np.dot(P.T,np.dot(np.diag(mask_i),Umatrix[:,i])))\n",
    "        err = np.sum((mask*(Umatrix-np.dot(P,Qt)))**2)#不断迭代，直至误差小于设定值\n",
    "        if err<tol:\n",
    "            break\n",
    "    return np.round(np.dot(P,Qt),0)\n",
    "#随机梯度下降（SGD）,也属于矩阵分解类别\n",
    "def SGD(Umatrix,K,iterations=100,alpha=0.00001,l=0.001,tol=0.001):\n",
    "    nrows = len(Umatrix)\n",
    "    ncols = len(Umatrix[0])\n",
    "    P = np.random.rand(nrows,K)\n",
    "    Q = np.random.rand(ncols,K)\n",
    "    Qt = Q.T\n",
    "    cost = -1\n",
    "    for it in range(iterations):\n",
    "        for j in range(ncols):\n",
    "            if Umatrix[i][j]>0:\n",
    "                eij = Umatrix[i][j]-np.dot(P[i,:],Qt[:,j])\n",
    "                for k in range(K):\n",
    "                    P[i][k] += alpha*(2*eij*Qt[k][j]-l*P[i][k])\n",
    "                    Qt[k][j] += alpha*(2*eij*P[i][k]-l*Qt[k][j])\n",
    "        cost = 0\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                if Umatrix[i][j]>0:\n",
    "                    cost += pow(Umatrix[i][j]-np.dot(P[i,:],Qt[:,j]),2)\n",
    "                    for k in range(K):\n",
    "                        cost+=float(1/2.0)*(pow(P[i][k],2)+pow(Qt[k][j],2))\n",
    "        if cost<tol:\n",
    "            break    \n",
    "    return np.round(np.dot(P,Qt),0)\n",
    "#非负矩阵分解（NMF）\n",
    "#这里没有进行重写，直接调用sklearn库中的NMF函数\n",
    "from sklearn.decomposition import NMF\n",
    "def NMF_alg(Umtrix,K,inp='none',l=0.001):\n",
    "    R_tmp = copy.copy(Umatrix)\n",
    "    R_tmp = R_tmp.astype(float)\n",
    "    if inp!='none':\n",
    "        R_tmp = imputation(inp,Umatrix)#缺失值处理\n",
    "    nmf = NMF(n_components=K,alpha=l)\n",
    "    P = nmf.fit_transform(R_tmp)\n",
    "    R_tmp = np.dot(P,nmf.components_)\n",
    "    return R_tmp\n",
    "#奇异值分解（SVD），特征降维方法\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def SVD(Umatrix,x,inp='none'):\n",
    "    R_tmp = copy.copy(Umatrix)\n",
    "    R_tmp = R_tmp.astype(float)\n",
    "    if inp!='none':\n",
    "        R_tmp = imputation(inp,Umatrix)#缺失值处理\n",
    "    means = np.array([R_tmp[i][R_tmp[i]>0].mean()for i in range(len(R_tmp))]).reshape(-1,1)\n",
    "    R_tmp = R_tmp-means   #进行奇异值分解之前将数值减去该行的平均值，是算法效果更好\n",
    "    svd = TruncatedSVD(n_components=K,random_state=4)\n",
    "    R_k = svd.fit_transform(R_tmp)\n",
    "    R_tmp = svd.inverse_transform(R_k)\n",
    "    R_tmp = means+R_tmp\n",
    "    return np.round(R_tmp,0)\n",
    "def SVD_gm(Umatrix,K,inp='none',iterations=50,tol=0.01):\n",
    "    R_tmp = copy.copy(Umatrix)\n",
    "    R_tmp = R_tmp.astype(float)\n",
    "    nrows = len(Umatrix)\n",
    "    ncols = len(Umatrix[0])\n",
    "    if inp!='none':\n",
    "        R_tmp = imputation(inp,Umatrix)#缺失值处理\n",
    "    \n",
    "    svd = TruncatedSVD(n_cimponents=K,random_state=4)\n",
    "    err = -1\n",
    "    for it in range(iterations):\n",
    "        R_k = svd.fit_transform(R_tmp)\n",
    "        R_tmp = svd.inverse_transform(R_k) \n",
    "        err = 0\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                if Umatrix[i][j]>0:\n",
    "                    err+=pow(Umatrix[i][j]-R_tmp[i][j],2)\n",
    "                    R_tmp[i][j] = Umatrix[i][j]\n",
    "        if err<tol:\n",
    "            print(it,'toll reached')\n",
    "            break\n",
    "    return np.round(R_tmp,0) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0de1a611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  movie_id unknown Action Adventure Animation Children's Comedy Crime  \\\n",
      "0        1       0      0         0         1          1      1     0   \n",
      "1        2       0      1         1         0          0      0     0   \n",
      "2        3       0      0         0         0          0      0     0   \n",
      "3        4       0      1         0         0          0      1     0   \n",
      "4        5       0      0         0         0          0      0     1   \n",
      "\n",
      "  Documentary Drama Fantasy Film-Noir Horror Musical Mystery Romance Sci-Fi  \\\n",
      "0           0     0       0         0      0       0       0       0      0   \n",
      "1           0     0       0         0      0       0       0       0      0   \n",
      "2           0     0       0         0      0       0       0       0      0   \n",
      "3           0     1       0         0      0       0       0       0      0   \n",
      "4           0     1       0         0      0       0       0       0      0   \n",
      "\n",
      "  Thriller War Western  \n",
      "0        0   0       0  \n",
      "1        1   0       0  \n",
      "2        1   0       0  \n",
      "3        0   0       0  \n",
      "4        1   0       0  \n"
     ]
    }
   ],
   "source": [
    "#5.4 CBF方法（基于内容的过滤方法）\n",
    "#从描述商品的数据中抽取用户的特征\n",
    "\n",
    "#构造二进制向量，并将其置于DataFrame对象中\n",
    "movieslist = [int(m.split(';')[-1]) for m in dfout.columns[1:]]\n",
    "moviescats = ['unknown','Action','Adventure','Animation','Children\\'s','Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western']\n",
    "dfout_movies =  pd.DataFrame(columns=['movie_id']+moviescats)\n",
    "startcatsindx = 5\n",
    "cnt= 0\n",
    "for m in movieslist:\n",
    "    dfout_movies.loc[cnt] = [m]+df_info.iloc[m-1][startcatsindx:].tolist()\n",
    "    cnt +=1 \n",
    "print(dfout_movies.head())\n",
    "\n",
    "dfout_movies.to_csv('./data/movies_content.csv',index=None)\n",
    "\n",
    "#5.4.1商品特征平均得分方法\n",
    "class CBF_averageprofile(object):\n",
    "    def __init__(self,Movies,Movieslist):\n",
    "        self.nfeatures = len(Movies[0])\n",
    "        self.Movieslist = Movieslist\n",
    "        saelf.Movies = Movies\n",
    "    def GetRecMovies(self,u_vec,indxs=False):   #构造函数生成用户喜欢的电影类型向量，返回与该向量最相似的电影\n",
    "        nmovies = len(u_vec)\n",
    "        nfeatures = self.nfeatures\n",
    "        mean_u = u_vec[u_vec>0].mean()\n",
    "        diff_u = u_vec-mean_u\n",
    "        features_u = np.zeros(nfeatures).astype(float)\n",
    "        cnts = np.zeros(nfeatures)\n",
    "        for m in range(nmovies):         #计算电影书，为下一步计算均值做准备\n",
    "            if cnts[m]>0:\n",
    "                features_u+= self.Movies[m]*(diff_u[m])\n",
    "                cnts += self.Movies[m]\n",
    "        for m in range(nfeatures):        #计算均值\n",
    "            if cnts[m]>0:\n",
    "                features_u[m] = features_u[m]/float(cnts[m])\n",
    "        sims = np.zeros(nmovies)         #计算相似度\n",
    "        for m in range(nmovies):\n",
    "            if u_vec[m] == 0:\n",
    "                sims[m] = sim(features_u,self.Movies[m])\n",
    "        order_Movies_indxs = np.argsort(sims)[::-1]\n",
    "        if indxs:\n",
    "            return order_movies_indxs\n",
    "        return self.Movieslist[order_movies_indxs]\n",
    "    \n",
    " #5.4.2正则化线性回归方法\n",
    "class CBF_regression(object):\n",
    "    def __init__(self,Movies,Umatrix,alpha=0.01,l=0.0001,its=50,tol=0.001):\n",
    "        self.nfeatures = len(Movies[0])+l\n",
    "        nusers = len(Umatrix)\n",
    "        nmovies = len(Umatrix[0])\n",
    "        movies_feats = np.ones((nmovies,self.nfeatures))\n",
    "        movies_feats[:,1:] = Movies\n",
    "        saelf.movies_feats = movies_feats.astype(float)\n",
    "        self.Umatrix = Umatrix.astype(float)          #使用梯度下降方法寻找参数sitar，即Pmatrix\n",
    "        Pmatrix = np.random.rand(nusers,self.nfeatures)\n",
    "        Pmatrix[:,0] = 1\n",
    "        err=0\n",
    "        cost = -1\n",
    "        for it in range(its):\n",
    "            print('its:',it,'--',cost)\n",
    "        for u in range(nusers):\n",
    "            for f in range(self.nfeatures):\n",
    "                if f==0:\n",
    "                    for m in range(nmovies):\n",
    "                        if self.Umatrix[u,m]> 0:\n",
    "                            diff = np.dot(Pmatrix[u],self.movies_feats[m])-self.Umatrix[u,m]\n",
    "                            Pmatrix[u,f] += -alpha*(diff*self.movies_feats[m][f])\n",
    "                else:\n",
    "                    for m in range(nmovies):\n",
    "                        if self.Umatrix[u,m]>0:\n",
    "                            diff = np.dot(Pmatrix[u],self.movies_feats[m])-self.Umatrix[u,m]\n",
    "                            Pmatrix[u,f] += -alpha*(diff*self.movies_feats[m][f]+l*Pmatrix[u][f])\n",
    "        cost = 0\n",
    "        for u in range(nusers):\n",
    "            for m in range(nmovies):\n",
    "                if self.Umatrix[u][m]>0:\n",
    "                    cost+=0.5*pow(Umatrix[u][m]-np.dot(Pmatrix[u],self.movies_feats[m]),2)\n",
    "            for f in range(1,self.nfeatures):\n",
    "                cost += float(1/2.0)*pow((Pmatrix[u][f],2))\n",
    "            if cost<tol:\n",
    "                print(\"err\",cost)\n",
    "                break\n",
    "        self.Pmatrix = Pmatrix\n",
    "    def CalcRatings(self,u_vec):    #从效用矩阵R中与用户向量计算相似度量，找出最相似的分数向量\n",
    "        s = 0.\n",
    "        u_feats = np.zeros(len(self.Pmatrix[0]))\n",
    "        \n",
    "        for u in range(len(self.Umatrix)):\n",
    "            tmps = sim(self.Umatrix[u],u_vec)\n",
    "            if tmps>s:\n",
    "                s = tmps\n",
    "                u_feats = self.Pmatrix[u]\n",
    "            if s == 1.:\n",
    "                break\n",
    "        new_vec = np.zeros(len(u_vec))\n",
    "        for r in range(len(u_vec)):\n",
    "            if u_vec[r]==0:\n",
    "                new_vec[r] = np.dot(u_feats,self.movies_feats[r])\n",
    "        return new_vec\n",
    "#使用关联规则学习，构建推荐系统\n",
    "#主要思想：统计交易数据库T中商品的出现情况，找到商品中的关系\n",
    "#支持度（包含一组商品X的交易数据站总交易数据的比例）置信度（同时包含XY的交易数据占只包含X的比例）\n",
    "\n",
    "class AssociationRules(object):\n",
    "    def __init__(self,Umatrix,Movieslist,min_support=0.1,min_confidence=0.1,likethreshold=3):\n",
    "        self.min_support = min_support   #支持度阈值\n",
    "        self.Movieslist = Movieslist\n",
    "        nitems = len(Umatrix[0])\n",
    "        transactions = []\n",
    "        for u in Umatrix:\n",
    "            s = [i for i in range(len(u)) if u[i]>likethreshold]\n",
    "            if len(s)>0:\n",
    "                transactions.append(s)\n",
    "        flat = [item for sublist in transactions for item in sublist]\n",
    "        inititems = map(frozenset,[[item] for item in frozenset(flat)])\n",
    "        set_trans = map(set,transactions)\n",
    "        sets_init,self.dict_sets_support = self.filterSet(set_trans,inititems)\n",
    "        setlen = 2\n",
    "        item_tmp = self.combine_lists(sets_init,setlen)\n",
    "        self.freq_sets,suo_tmp = self.filterSet(set_trans,item_tmp)\n",
    "        self.ass_matrix = np.zeros(nitems,nitems)\n",
    "        for freqset in self.freq_sets:\n",
    "            list_setitems = [frozenset([item])for item in freqset]\n",
    "            self.calc_confidence_matrix(freqset,list_setitems)\n",
    "            \n",
    "    def filterSet(self,set_trans,likeditems):  #用于过滤规则\n",
    "        itemscnt = {}\n",
    "        for id in set_trans:\n",
    "            for item in likeditems:\n",
    "                if item.issunset(id):\n",
    "                    itemscnt.setdefault(item,0)\n",
    "                    itemscnt[item] += 1\n",
    "        num_items = float(len(set_trans))\n",
    "        freq_sets = []\n",
    "        dict_sets = {}\n",
    "        for key in itemscnt:\n",
    "            support = itemcnt[key]/num_items\n",
    "            if support>=self.min_support:\n",
    "                freq_sets.insert(0,key)\n",
    "            dict_sets[key] = support\n",
    "        return freq_sets,dict_sets\n",
    "    def combine_lists(self,freq_sets,setlen):  #寻找所有可能的规则\n",
    "        setitems_list = []\n",
    "        nsets = len(freq_sets)\n",
    "        for i in range(nsets):\n",
    "            setlist1 = list(freq_sets[i])[:setlen-2]\n",
    "            setlist2 = list(freq_sets[j])[:setlen-2]\n",
    "            if set(setlist)==set(setlist2):\n",
    "                setitems_list.append(freq_sets[i].union(freq_sets[j]))\n",
    "        return set_items_list\n",
    "    def calc_confidence_matrix(self,freqset,list_setitems):\n",
    "        for target in list_setitems:#用满足最小阈值的置信度填充ass_matrix矩阵\n",
    "            confidence = self.dict_sets_support[freqset]/self.dict_sets_support[freqsets-target]\n",
    "            if confidence >= self.min_confidence:\n",
    "                self.ass_matrix[list(freqset-target)[0]][list(target)[0]]=confidence\n",
    "    \n",
    "    def GetRecItems(self,u_vec,indxs=False):   #根据用户打的分数u_vec返回一个电影推荐列表\n",
    "        vec_recs = np.dot(u_vec,self.ass_matrix)\n",
    "        sortedweight = np.argsort(vec_recs)\n",
    "        seenindxs = [indx for indx in range(len(u_vec))if u_vec[indx]>0]\n",
    "        seenmovies = np.array(self.Movieslist)[seenindx]\n",
    "        recitems = np.array(self.Movieslist)[sortedweight]\n",
    "        recitems = [m for m in recitems if m not in seenmovies]\n",
    "        if indx:\n",
    "            vec_recs[seenindxs] = -1\n",
    "            recsvec = np.argsort(vec_recs)[::-1][np.argsort(vec_recs)>0]\n",
    "            return recsvec\n",
    "        return recitems[::-1]\n",
    "#5.6对数似然比推荐方法\n",
    "#对数似然比（LLr）是度量事件AB不太可能是独立事件而是共现几率大于偶然的一种方法\n",
    "class LogLikelihood(object):\n",
    "    def __init__(self,Umatrix,Movieslist,likethreshold=3):\n",
    "        self.Movieslist = Movieslist\n",
    "        self.nusers = len(Umatrix)\n",
    "        self.Umatrix = Umatrix\n",
    "        self.likethreshold = likethreshold\n",
    "        self.likerage = range(self.likethreshold+1,5+1)\n",
    "        self.dislikerange = range(1,self.likethreshold)\n",
    "        self.loglikelihood_ratio()\n",
    "        \n",
    "    def calc_k(self,a,b):\n",
    "        tmpk = [[0 for j in range(2)]for i in range(2)]#构造二项分布矩阵K\n",
    "        for ratings in self.Umatrix:\n",
    "            if ratings[a] in self.likerage and ratings[b] in self.likerage:\n",
    "                tmpk[0][0]+=1\n",
    "            if ratings[a] in self.likerage and ratings[b] in self.dislikerange:\n",
    "                tmpk[0][1]+=1\n",
    "            if ratings[a] in self.dislikerange and ratings[b] in self.likerage:\n",
    "                tmpk[1][0]+=1\n",
    "            if ratings[a] in self.dislikerange and ratings[b] in self.dislikerange:\n",
    "                tmpk[1][1]+=1\n",
    "        return tmpk\n",
    "    def calc_llr(self,k_matrix):\n",
    "        Hcols = Hrows = Htot = 0.0\n",
    "        if sum(k_matrix[0])+sum(k_matrix[1])==0:\n",
    "            return 0\n",
    "        invN = 1.0/(sum(k_matrix[0])+sum(k_matrix[1]))\n",
    "        for i in range(0,2):                     \n",
    "            if((k_matrix[0][i]+k_matrix[1][i])!=0.0):\n",
    "                Hcols += invN*(k_matrix[0][i]+k_matrix[1][i])*math.log((k_matrix[0][i]+k_matrix[1][i])*invN)\n",
    "            if((k_matrix[i][0]+k_matrix[i][1])!=0.0):\n",
    "                Hrows += invN*(k_matrix[i][0]+k_matrix[i][1])*math.log((k_matrix[i][0]+k_matrix[i][1])*invN)\n",
    "            for j in range(0,2):\n",
    "                if(k_matrix[i][j]!=0.0):\n",
    "                    Htot += invN*(k_matrix[i][j]*math.log(invN*k_matrix[i][j]))\n",
    "        return 2.0*(Htot-Hcols-Hrows)/invN  #返回根据LLR计算公式得到的LLR值\n",
    "    def loglikelihood_ratio(self):   #用于计算矩阵K（即该函数中变量calc_k）以及相应的LLR（calc_llr）\n",
    "        nitems = len(self.Movieslist)\n",
    "        self.items_llr = pd.DataFrame(np.zeros((nitems,nitems))).astype(float)\n",
    "        for i in range(nitems):\n",
    "            for j in range(nitems):\n",
    "                if(j>=i):\n",
    "                    tmpk= self.calc_k(i,j)\n",
    "                    self.items_llr.loc[i,j] = self.calc_llr(tmpk)\n",
    "                else:\n",
    "                    self.items_llr.loc[i,j] = self.items_llr.iat[j,i]\n",
    "    def GetRecItems(self,u_vec,indxs=False):\n",
    "        items_weight = np.dot(u_vec,self.items_llr)\n",
    "        sortedweight = np.argsort(items_weight)\n",
    "        seenindxs = [indx for indx in range(len(u_vec))if u_vec[indx]>0]\n",
    "        seenmovies = np.array(self.Movieslist)[seenindx]\n",
    "        recitems = np.array(self.Movieslist)[sortedweight]\n",
    "        recitems = [m for m in recitems if m not in seenmovies]\n",
    "        if indx:\n",
    "            items_weight[seenindxs] = -1\n",
    "            recsvec = np.argsort(items_weight)[::-1][np.argsort(vec_recs)>0]\n",
    "            return recsvec\n",
    "        return recitems[::-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc4f0bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (Temp/ipykernel_37436/2824200769.py, line 81)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_37436/2824200769.py\"\u001b[1;36m, line \u001b[1;32m81\u001b[0m\n\u001b[1;33m    return u_rec\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "#5.7混合推荐系统\n",
    "#混合使用CBF和CF方法\n",
    "#加权（CBF和CF预测分数取加权平均值）混合（CF与CBF预测结果合并为一个列表）\n",
    "#切换（根据特地特定规则选择使用）特征组合（综合CF与CBF特征找到最相似的用户或商品）\n",
    "#特阵扩充（类似于特征组合+附加特征预测分数）\n",
    "\n",
    "#方法一：基于用户的CF，扩展效用矩阵，增加每位用户的平均分\n",
    "class Hybird_cbf_cf(object):\n",
    "    def __init__(self,Movies,Movieslist,Umatrix):\n",
    "        self.nfeatures = len(Movies[0])\n",
    "        self.movieslist = Movieslist\n",
    "        self.Movies = Movies.astype(float)\n",
    "        self.Umatrix_mfeats = np.zeros((len(Umatrix),len(Umatrix[0])+self.nfeatures))\n",
    "        means = np.array([Umatrix[i][Umatrix[i]>0].mean()for i in range(len(Umatrix))]).reshape(-1,1)\n",
    "        diffs = np.array([[Umatrix[i][j]-means[i] if Umatrix[i][j]>0 else 0.\n",
    "                          for j in range(len(Umatrix[i]))]for i in range(len(Umatrix))])\n",
    "        self.Umatrix_mfeats[:,:len(Umatrix[0])] = Umatrix\n",
    "        self.nmovies = len(Movies)\n",
    "        for u in range(len(Umatrix)):\n",
    "            u_vec = Umatrix[u]\n",
    "            self.Umatrix_mfeats[u,len(Umatrix[0]):] = self.GetUserItemFeatures(u_vec)\n",
    "    def GetUserItemFeatures(self,u_vec):\n",
    "        mean_u = u_vec[u_vec>0].mean()\n",
    "        features_u = np.zeros(self.nfeatures).astype(float)\n",
    "        cnts = np.zeros(self.nfeatures)\n",
    "        for m in range(self.nmovies):\n",
    "            if u_vec[m]>0:\n",
    "                features_u += self.Movies[m]*u_vec[m]\n",
    "                cnts+=self.Movies[m]\n",
    "        for m in range(self.nfeatures):\n",
    "            if cnts[m]>0:\n",
    "                features_u[m]=features_u[m]/float(cnts[m])\n",
    "        return features_u\n",
    "    \n",
    "    def CalcRating(u_vec,r,neighs):  #使用皮尔逊相关系数度量方法，比较每一位用户扩展后的特征向量\n",
    "        rating=0.\n",
    "        den=0.\n",
    "        for j in range(len(neighs)):\n",
    "            rating+=neighs[j][-1]*float(neighs[j][r]-neighs[j][neighs[j]>0][:-1].mean())\n",
    "            den+=abs(neighs[j][-1])\n",
    "        if den>0:\n",
    "            rating = np.round(u_vec[u_vec>0].mean()+[rating/den],0)\n",
    "        else:\n",
    "            rating = np.round(u_vec[u_vec>0].mean())\n",
    "        if rating>5:\n",
    "            return 5\n",
    "        elif rating<1:\n",
    "            return 1\n",
    "        return rating\n",
    "    nrows = len(self.Umatrix_mfeats)\n",
    "    ncols = len(self.Umatrix_mfeats[0])\n",
    "    data_sim = np.zeros((nrows,ncols+1))\n",
    "    data_sim[:,:-1] = self.Umatrix_mfeats\n",
    "    u_rec = np.zeros(len(u_vec))\n",
    "    mean = u_vec[u_vec>0].mean()\n",
    "    u_vec_feats = u_vec\n",
    "    u_vec_feats = np.append(u_vec_feats,self.GetUserItemFeatures(u_vec))\n",
    "    for u in range(nrows):\n",
    "        if np.array_equal(data_sim[u,:-1],u_vec)==False:\n",
    "            data_sim[u,ncols] = sim(data_sim[u,:-1],u_vec_feats)\n",
    "        else:\n",
    "            data_sim[u,ncols] = 0\n",
    "    data_sim[:,:-1] = self.Umatrix_mfeats\n",
    "    u_rec = np.zeros(len(u_vec))\n",
    "    mean = u_vec[u_vec>0].mean()\n",
    "    u_vec_feats = u_vec\n",
    "    u_vec_feats = np.append(u_vec_feats,self.GetUserItemFeatures(u_vec))\n",
    "\n",
    "    for u in range(nrows):\n",
    "        if np.array_equal(data_sim[u,:-1],u_vec) == False:\n",
    "            data_sim[u,ncols] = sim(data_sim[u,:-1],u_vec_feats)\n",
    "        else:\n",
    "            data_sim[u,ncols] = 0\n",
    "\n",
    "    data_sim = data_sim[data_sim[:,ncols].argsort()][::-1]\n",
    "\n",
    "    for r in range(self.nmovies):#调用K近邻算法找出K个近邻\n",
    "        if u_vec[r]==0:\n",
    "            neighs = FindKNeighbours(r,data_sim,K)\n",
    "            u_rec[r] = CalcRatings(u_vec,r,neighs)\n",
    "    return u_rec\n",
    "#  方法二：使用SVD（奇异值分解）方法扩展效用矩阵\n",
    "class Hybird_svd(object):\n",
    "    def __init__(self,Movies,Movieslist,Umatrix,K,inp):\n",
    "        self.nfeatures = len(Movies)\n",
    "        self.Movieslist = Movieslist\n",
    "        self.Movies = Movies.astype(float)\n",
    "        R_tmp = copy.copy(Umatrix)\n",
    "        R_tmp = R_tmp.astype(float)\n",
    "        if inp!='none':\n",
    "            R_tmp = imputation(inp,Umatrix)#缺失值处理\n",
    "        means = np.array([Umatrix[i][Umatrix[i]>0].mean()for i in range(len(Umatrix))]).reshape(-1,1)\n",
    "        diffs = np.array([[float(Umatrix[i][j]-means[i])\n",
    "                          if Umatrix[i][j]>0 else float(R_tmp[i][j]-means[i])\n",
    "                          for j in range(len(Umatrix[i]))]\n",
    "                         for i in range(len(Umatrix))])\n",
    "        Umatrix_mfeats[:,:len(Umatrix[0])] = diffs\n",
    "        self.nmovies = len(Movies)\n",
    "        for u in range(len(Umatrix)):\n",
    "            u_vec = Umatrix[u]\n",
    "            Umatrix_mfeats[u,len(Umatrix[0]):] = self.GetUserItemFeatures(u_vec)\n",
    "        \n",
    "        svd = TruncatedSVD(n_components=K,random_stats=4)\n",
    "        R_k = svd.fit_transform(Umatrix_mfeats)\n",
    "        R_tmp = means+svd.inverse_transform(R_k)\n",
    "        self.matrix = np.round(R_tmp[:,:self.nmovies],0)\n",
    "    def GetUserItemFeatures(self,u_vec):\n",
    "        mean_u = u_vec[u_vec>0].mean()\n",
    "        diff_u = u_vec-mean_u\n",
    "        features_u = np.zeros(self.nfeatures).astype(float)\n",
    "        cnts = np.zeros(self.nfeatures)\n",
    "        for m in range(self.nmovies):\n",
    "            if u_vec[m]>0:\n",
    "                features_u += self.Movies[m]*(diff_u[m])\n",
    "                cnts+=selfself.Movies[m]\n",
    "        for m in range(self.nfeatures):\n",
    "            if cnts[m]>0:\n",
    "                features_u[m] = features_u[m]/float(vnts[m])\n",
    "        return features_u\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0d45c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  Toy Story (1995);1  GoldenEye (1995);2  Four Rooms (1995);3  \\\n",
      "0     1                   5                   3                    4   \n",
      "1     2                   4                   0                    0   \n",
      "2     3                   0                   0                    0   \n",
      "3     4                   0                   0                    0   \n",
      "4     5                   4                   3                    0   \n",
      "\n",
      "   Get Shorty (1995);4  Copycat (1995);5  Twelve Monkeys (1995);7  \\\n",
      "0                    3                 3                        4   \n",
      "1                    0                 0                        0   \n",
      "2                    0                 0                        0   \n",
      "3                    0                 0                        0   \n",
      "4                    0                 0                        0   \n",
      "\n",
      "   Babe (1995);8  Dead Man Walking (1995);9  Richard III (1995);10  ...  \\\n",
      "0              1                          5                      3  ...   \n",
      "1              0                          0                      2  ...   \n",
      "2              0                          0                      0  ...   \n",
      "3              0                          0                      0  ...   \n",
      "4              0                          0                      0  ...   \n",
      "\n",
      "   Cool Runnings (1993);1035  Hamlet (1996);1039  Forget Paris (1995);1041  \\\n",
      "0                          0                   0                         0   \n",
      "1                          0                   0                         0   \n",
      "2                          0                   0                         0   \n",
      "3                          0                   0                         0   \n",
      "4                          0                   0                         0   \n",
      "\n",
      "   Multiplicity (1996);1047  She's the One (1996);1048  \\\n",
      "0                         0                          0   \n",
      "1                         0                          0   \n",
      "2                         0                          0   \n",
      "3                         0                          0   \n",
      "4                         0                          0   \n",
      "\n",
      "   Koyaanisqatsi (1983);1065  Shallow Grave (1994);1073  \\\n",
      "0                          0                          0   \n",
      "1                          0                          0   \n",
      "2                          0                          0   \n",
      "3                          0                          0   \n",
      "4                          0                          0   \n",
      "\n",
      "   Reality Bites (1994);1074  Six Degrees of Separation (1993);1101  \\\n",
      "0                          0                                      0   \n",
      "1                          0                                      0   \n",
      "2                          0                                      0   \n",
      "3                          0                                      0   \n",
      "4                          0                                      0   \n",
      "\n",
      "   Some Kind of Wonderful (1987);1119  \n",
      "0                                   0  \n",
      "1                                   0  \n",
      "2                                   0  \n",
      "3                                   0  \n",
      "4                                   0  \n",
      "\n",
      "[5 rows x 604 columns]\n",
      "check::: 603 -- 603\n",
      "188\n"
     ]
    }
   ],
   "source": [
    "#5.8推荐系统评估\n",
    "#使用K这交叉检验验证结果的客观性\n",
    "def cross_validation(df,k):\n",
    "    val_num = int(len(df)/float(k))\n",
    "    print(val_num)\n",
    "    df_trains = []\n",
    "    df_vals = []\n",
    "    for i in range(k):\n",
    "        start_val = (k-i-1)*val_num\n",
    "        end_val = start_val+val_num\n",
    "        df_trains.append(pd.concat([df[:start_val],df[end_val:]]))\n",
    "        df_vals.append(df[start_val:end_val])\n",
    "    return df_trains,df_vals\n",
    "import random\n",
    "def HideRandomRatings(u_vec,ratiovals=0.5):\n",
    "    u_test = np.zeros(len(u_vec))\n",
    "    u_vals = np.zeros(len(u_vec))\n",
    "    cnt = 0\n",
    "    nratings = len(u_vec[u_vec>0])\n",
    "    for i in range(len(u_vec)):\n",
    "        if u_vec[i]>0:\n",
    "            if bool(random.getrandbits(1))or cnt>=int(nratings*ratiovals):\n",
    "                u_test[i] = u_vec[i]\n",
    "            else:\n",
    "                cnt+=1\n",
    "                u_vals[i] = u_vec[i]\n",
    "    return u_test,u_vals  #u_vals存储的是预测值，u_test存储用于测试算法的实际分数\n",
    "#读取数据\n",
    "df = pd.read_csv('./data/utilitymatrix.csv')\n",
    "print(df.head())\n",
    "df_movies = pd.read_csv('./data/movies_content.csv')\n",
    "movies = df_movies.values[:,1:]\n",
    "print('check:::',len(df.columns[1:]),'--',len(df_movies))\n",
    "movieslist = list(df.columns[1:])\n",
    "nfolds = 5            #调用自定义的K折检验函数\n",
    "df_trains,df_vals = cross_validation(df,nfolds)\n",
    "\n",
    "nmovies =  len(df_vals[0].values[:,1:][0])\n",
    "s = []\n",
    "tests_vecs_folds = []\n",
    "vals_vecs_folds = []\n",
    "for i in range(nfolds):\n",
    "    u_vecs = df_vals[i].values[:,1:]\n",
    "    vtests = np.empty((0,nmovies),float)\n",
    "    vvals = np.empty((0,nmovies),float)\n",
    "    for u_vec in u_vecs:\n",
    "        u_test,u_vals = HideRandomRatings(u_vec)\n",
    "        vvals = np.vstack([vvals,u_vals])\n",
    "        vtetss = np.vstack([vtests,u_test])\n",
    "    vals_vecs_folds.append(vvals)\n",
    "    tests_vecs_folds.append(vtests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74d9e14b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CF_itembased() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_37436/178985447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mUmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mcfitembased\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCF_itembased\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mcfslopeone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSlopeOne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fold:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: CF_itembased() takes no arguments"
     ]
    }
   ],
   "source": [
    "#5.8.1均方根误差评估（RMSE）（支持用于CF和线性回归CBF）\n",
    "def SE(u_preds,u_vals):\n",
    "    nratings = len(u_vals)\n",
    "    se = 0\n",
    "    cnt = 0\n",
    "    for i in range(nratings):\n",
    "        if u_vals[i]>0:\n",
    "            se += (u_vals[i]-u_preds[i])*(u_vals[i]-u_preds[i])\n",
    "            cnt+=1\n",
    "    return se,cnt\n",
    "\n",
    "err_itembased = 0.\n",
    "cnt_itembased = 0\n",
    "err_userbased = 0.\n",
    "cnt_userbased = 0\n",
    "err_slopeone = 0.\n",
    "cnt_slopeone = 0\n",
    "err_cbfcf = 0.\n",
    "cnt_cbfcf = 0\n",
    "for i in range(nfolds):\n",
    "    Umatrix = df_trains[i].values[:,1:]\n",
    "    cfitembased = CF_itembased(Umatrix)\n",
    "    cfslopeone = SlopeOne(Umatrix)\n",
    "    print('fold:',i+1)\n",
    "    vec_vals = vals_vecs_folds[i]\n",
    "    vec_tests = tests_vecs_folds[i]\n",
    "    for j in range(len(vec_vals)):\n",
    "        u_vals = vec_vals[j]\n",
    "        u_test = vec_tests[j]\n",
    "        \n",
    "        u_preds = cbfcf.CalcRatings(u_test,5)\n",
    "        e,c = SE(u_preds,u_vals)\n",
    "        err_cbfcf += e\n",
    "        cnt_cbfcf += c\n",
    "        \n",
    "        u_preds = CF_userbased(u_test,5,Umatrix)\n",
    "        e,c = SE(u_preds,u_vals)\n",
    "        err_userbased += e\n",
    "        cnt_userbased += c\n",
    "        \n",
    "        u_preds = cfitembased.CalcRatings(u_test,5)\n",
    "        e,c = SE(u_preds,u_vals)\n",
    "        err_itembased += e\n",
    "        cnt_itembased += c\n",
    "        \n",
    "        u_pred = cfslopeone.CalcRatings(u_test,5)\n",
    "        e,c = SE(u_preds,u_vals)\n",
    "        err_slopeone += e\n",
    "        cnt_slopeone += c\n",
    "rmse_userbased = np.sqrt(err_userbased/float(cnt_userbased))\n",
    "rmse_itembased = np.sqrt(err_itembased/float(cnt_itembased))\n",
    "rmse_slopeone = np.sqrt(err_slopeone/float(cnt_slopeone))\n",
    "print('user_userbased rmse:',rmse_userbased,'--',cnt_userbased)\n",
    "print('user_itembased rmse:',rmse_itembased,'--',cnt_itembased)\n",
    "print('slope one rmse:',rmse_slopeone,'--',cnt_slopeone)\n",
    "\n",
    "rmse_cbfcf = np.sqrt(err_cbfcf/float(cnt_cbfcf))\n",
    "print('cbfcf rmse',rmse_cbfcf,'--',cnt_cbfcf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2bb102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.2分类效果的度量方法\n",
    "def ClassificationMetrics(vec_vals,vec_recs,likethreshold=3,shortlist=50,ratingsval=False,vec_test=None):\n",
    "    indxs_like = [i for i in range(len(vec_vals))if vec_vals[i]>likethreshold]\n",
    "    indxs_dislike = [i for i in range(len(vec_vals))if vec_vals[i]<=likethreshold and vec_vals[i]>0]\n",
    "    cnt = len(indxs_like)+len(indxs_dislike)\n",
    "    indxs_rec = []\n",
    "    if ratingsval:\n",
    "        if vec_test == None:\n",
    "            raise('Error no test vector')\n",
    "            indxs_rec = [i for i in range(len(vec_recs))if vec_recs[i]>likethreshold and vec_test[i]<1][:shortlist]\n",
    "        else:\n",
    "            indxs_rec = vec_recs[:shortlist]\n",
    "        tp = len(set(indxs_rec).intersection(set(indxs_like)))\n",
    "        fp = len(set(indxs_rec).intersection(set(indxs_dislike)))\n",
    "        fn = len(set(indxs_like)^(set(indxs_rec).intersection(set(indxs_like))))\n",
    "        precision = 0.\n",
    "        if tp+fp>0:\n",
    "            precision = float(tp)/(tp+fp)\n",
    "        recall = 0\n",
    "        if tp+fn>0:\n",
    "            recall = float(tp)/(tp+fn)\n",
    "        f1 = 0\n",
    "        if recall_precision>0:\n",
    "            f1 = 0.*precision*recall/(precision+recall)\n",
    "        return ap.array([precision,recall,f1]).cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
